{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import treebank\n",
    "from nltk.corpus import conll2000\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "treebank_corpus = treebank.tagged_sents(tagset='universal')\n",
    "brown_corpus = brown.tagged_sents(tagset='universal')\n",
    "conll_corpus = conll2000.tagged_sents(tagset='universal')\n",
    "tagged_sentences = treebank_corpus + brown_corpus + conll_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NOUN'),\n",
       " ('Vinken', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('61', 'NUM'),\n",
       " ('years', 'NOUN'),\n",
       " ('old', 'ADJ'),\n",
       " (',', '.'),\n",
       " ('will', 'VERB'),\n",
       " ('join', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('board', 'NOUN'),\n",
       " ('as', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('nonexecutive', 'ADJ'),\n",
       " ('director', 'NOUN'),\n",
       " ('Nov.', 'NOUN'),\n",
       " ('29', 'NUM'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # store input sequence\n",
    "Y = [] # store output sequence\n",
    "\n",
    "for sentence in tagged_sentences:\n",
    "    X_sentence = []\n",
    "    Y_sentence = []\n",
    "    for entity in sentence:         \n",
    "        X_sentence.append(entity[0])  # entity[0] contains the word\n",
    "        Y_sentence.append(entity[1])  # entity[1] contains corresponding tag\n",
    "        \n",
    "    X.append(X_sentence)\n",
    "    Y.append(Y_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59448\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "num_words = len(set([word.lower() for sentence in X for word in sentence]))\n",
    "num_tags   = len(set([word.lower() for sentence in Y for word in sentence]))\n",
    "print(num_words)\n",
    "print(num_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adj': 1, '.': 2, 'num': 3, 'x': 4, 'adv': 5, 'pron': 6, 'prt': 7, 'det': 8, 'conj': 9, 'noun': 10, 'verb': 11, 'adp': 12}\n"
     ]
    }
   ],
   "source": [
    "unique_tags = list(set([word.lower() for sentence in Y for word in sentence]))\n",
    "unique_tags_dict = {}\n",
    "index = 1\n",
    "for tag in unique_tags:\n",
    "    unique_tags_dict[tag] = index \n",
    "    index += 1\n",
    "print(unique_tags_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59448\n"
     ]
    }
   ],
   "source": [
    "unique_words = list(set([word.lower() for sentence in X for word in sentence]))\n",
    "unique_words_dict = {}\n",
    "index = 1\n",
    "for word in unique_words:\n",
    "    unique_words_dict[word] = index \n",
    "    index += 1\n",
    "print(len(unique_words_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    \"\"\"Input: takes in a list of words, and a dictionary containing the index of the words\n",
    "    Output: a tensor containing the indexes of the word\"\"\"\n",
    "    idxs = [to_ix[w.lower()] for w in seq]\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "def split(list_a, batch_size):\n",
    "\n",
    "  for i in range(0, len(list_a), batch_size):\n",
    "    yield list_a[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "X_batches = list(split(X, batch_size))\n",
    "Y_batches = list(split(Y,batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batches_padded = []\n",
    "Y_batches_padded = []\n",
    "max_length_list = []\n",
    "\n",
    "for b_s,b_t in zip(X_batches,Y_batches):\n",
    "    max_seq_length = 0\n",
    "    for sentence in b_s:\n",
    "        if len(sentence) > max_seq_length:\n",
    "            max_seq_length = len(sentence)\n",
    "    \n",
    "    sen_encoded = []\n",
    "    tag_encoded = []\n",
    "    for sentence,tags in zip(b_s,b_t):\n",
    "        sen_encoded.append(prepare_sequence(sentence, unique_words_dict))\n",
    "        tag_encoded.append(prepare_sequence(tags, unique_tags_dict))\n",
    "    \n",
    "    X_batches_padded.append(pad_sequences(sen_encoded, maxlen=max_seq_length, padding=\"pre\", truncating=\"post\"))\n",
    "    Y_batches_padded.append(pad_sequences(tag_encoded, maxlen=max_seq_length, padding=\"pre\", truncating=\"post\"))\n",
    "    max_length_list.append(max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9026\n",
      "9026\n",
      "9026\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_batches_padded))\n",
    "print(len(X_batches_padded))\n",
    "print(len(max_length_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(Y_batches_padded[0]))\n",
    "len(X_batches_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10\n",
      "  10  2  3 10  1  2 11 11  8 10 12  8  1 10 10  3  2]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0 10 10 11 10 12 10 10  2  8 10 11 10  2]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 10 10  2  3 10  1  9  1 10 12\n",
      "  10 10 10 10  2 11 11  4  8  1 10 12  8  1  1 10  2]\n",
      " [ 8 10 12 10  5 11  4  4  7 11 10 10 10 11 11  8  1 10 12 10 10 12  8 10\n",
      "  12 10 11  4  7  6  5 12  3 10 12  2 10 11  4  4  2]\n",
      " [ 0  0  0  0  0  0  8 10 10  2 10  2 11  5  1 12  6 11  8 10  2 12  5  1\n",
      "  10  7  6 11 10  8  4 11  7 10  1  2 10 11  4  4  2]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 10 10  2  8 10 12  1  1 10 10\n",
      "   8  4 11 10 10  2 11 11 10 12  6 10 10 10 12  3  2]\n",
      " [ 0  0  0  0 12  1 10 11 11  4  5 12  8 10 12  2  8  1 10 11 12 10  7 10\n",
      "  10 10 12 10  2  8 10  1  4  7 11  1 10  7  8 10  2]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  8 10 10 11  2  2  8 11  8  1 10  2]]\n",
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0  6123\n",
      "  18217 51070 21817 57400 56718 51070 58036 33418 27769 18305 40453 25376\n",
      "   5030 12877  5910  8138 14849]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0 21892 18217 53864 32416 34367 47216 42055 51070\n",
      "  27769 32353     9  7463 14849]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0 29464 49536 51070  3062 57400 56718 10020 53154 32416 34367\n",
      "  58225 26761 17462 13845 51070 40220 36762 48581 25376  5030 12877 34367\n",
      "  43650 49075 37692 34546 14849]\n",
      " [25376 14995 34367 40522 53438 29444 21096 21096 22001 47553  8190 20431\n",
      "  52951 49698 43228 25376 14303   248 34367 10813  3258 44791 25376  7463\n",
      "  34367 46942  9680 21096 22001 30275  8692 59279 53470 57400 41398 51070\n",
      "   7799 37028 45577 57833 14849]\n",
      " [    0     0     0     0     0     0 27769 40522 15246 51070 41931 51070\n",
      "  53864 52726  1239 53438 30275 50281 27769 45873 51070 18589 24625 49880\n",
      "  44871 22001 30275  5125  3519  8462 57833 19241 48493  6751  9119 51070\n",
      "   7799 47988 45577 35707 14849]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0 48324  6932 51070 27769 46631 34367 27920 28742  8698 31802\n",
      "   8462 35707 56114  8190 48688 51070 14917  4365 41931  3291 16010 18666\n",
      "  20431 52951  3291 16223 14849]\n",
      " [    0     0     0     0 18026  3309  9254 18165 37028   341  8692 59279\n",
      "  25376 25870 41398 51070 27769 38954 15248 34075  3291  4428 26823 27920\n",
      "  39734 44734 34367 17755 51070 25376 24048   674 21096 22001 20805 27920\n",
      "  34788 22001 27769 23801 14849]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0 25376 48324 25260 47988 51070 39480 43650\n",
      "  53864 37104 56718 15821 14849]]\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "print(Y_batches_padded[0])\n",
    "print(X_batches_padded[0])\n",
    "print(max_length_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = []\n",
    "Y_final = []\n",
    "\n",
    "for index in range(len(X_batches_padded)):\n",
    "    X_batch_tensor = torch.zeros((batch_size,max_length_list[index]),dtype = int).to(device= device)\n",
    "    Y_batch_tensor = torch.zeros((batch_size,max_length_list[index]), dtype = int).to(device = device)\n",
    "\n",
    "    count = 0\n",
    "    for x, y in zip(X_batches_padded[index],Y_batches_padded[index]):\n",
    "        X_batch_tensor[count] = torch.tensor(x).to(device = device)\n",
    "        Y_batch_tensor[count] = torch.tensor(y).to(device =device)\n",
    "        count += 1\n",
    "    \n",
    "    X_final.append(X_batch_tensor)\n",
    "    Y_final.append(Y_batch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9026\n",
      "9026\n",
      "torch.Size([8, 41])\n",
      "torch.Size([8, 41])\n",
      "torch.Size([41])\n",
      "torch.Size([41])\n",
      "torch.Size([8, 38])\n",
      "torch.Size([8, 38])\n",
      "tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,  6123, 18217, 51070, 21817, 57400, 56718, 51070,\n",
      "         58036, 33418, 27769, 18305, 40453, 25376,  5030, 12877,  5910,  8138,\n",
      "         14849],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0, 21892, 18217,\n",
      "         53864, 32416, 34367, 47216, 42055, 51070, 27769, 32353,     9,  7463,\n",
      "         14849],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0, 29464, 49536, 51070,  3062, 57400, 56718,\n",
      "         10020, 53154, 32416, 34367, 58225, 26761, 17462, 13845, 51070, 40220,\n",
      "         36762, 48581, 25376,  5030, 12877, 34367, 43650, 49075, 37692, 34546,\n",
      "         14849],\n",
      "        [25376, 14995, 34367, 40522, 53438, 29444, 21096, 21096, 22001, 47553,\n",
      "          8190, 20431, 52951, 49698, 43228, 25376, 14303,   248, 34367, 10813,\n",
      "          3258, 44791, 25376,  7463, 34367, 46942,  9680, 21096, 22001, 30275,\n",
      "          8692, 59279, 53470, 57400, 41398, 51070,  7799, 37028, 45577, 57833,\n",
      "         14849],\n",
      "        [    0,     0,     0,     0,     0,     0, 27769, 40522, 15246, 51070,\n",
      "         41931, 51070, 53864, 52726,  1239, 53438, 30275, 50281, 27769, 45873,\n",
      "         51070, 18589, 24625, 49880, 44871, 22001, 30275,  5125,  3519,  8462,\n",
      "         57833, 19241, 48493,  6751,  9119, 51070,  7799, 47988, 45577, 35707,\n",
      "         14849],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0, 48324,  6932, 51070, 27769, 46631, 34367,\n",
      "         27920, 28742,  8698, 31802,  8462, 35707, 56114,  8190, 48688, 51070,\n",
      "         14917,  4365, 41931,  3291, 16010, 18666, 20431, 52951,  3291, 16223,\n",
      "         14849],\n",
      "        [    0,     0,     0,     0, 18026,  3309,  9254, 18165, 37028,   341,\n",
      "          8692, 59279, 25376, 25870, 41398, 51070, 27769, 38954, 15248, 34075,\n",
      "          3291,  4428, 26823, 27920, 39734, 44734, 34367, 17755, 51070, 25376,\n",
      "         24048,   674, 21096, 22001, 20805, 27920, 34788, 22001, 27769, 23801,\n",
      "         14849],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0, 25376,\n",
      "         48324, 25260, 47988, 51070, 39480, 43650, 53864, 37104, 56718, 15821,\n",
      "         14849]], device='cuda:0')\n",
      "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0, 10, 10,  2,  3, 10,  1,  2, 11, 11,  8, 10, 12,  8,\n",
      "          1, 10, 10,  3,  2],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10, 10, 11, 10, 12, 10, 10,  2,\n",
      "          8, 10, 11, 10,  2],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10, 10,  2,  3,\n",
      "         10,  1,  9,  1, 10, 12, 10, 10, 10, 10,  2, 11, 11,  4,  8,  1, 10, 12,\n",
      "          8,  1,  1, 10,  2],\n",
      "        [ 8, 10, 12, 10,  5, 11,  4,  4,  7, 11, 10, 10, 10, 11, 11,  8,  1, 10,\n",
      "         12, 10, 10, 12,  8, 10, 12, 10, 11,  4,  7,  6,  5, 12,  3, 10, 12,  2,\n",
      "         10, 11,  4,  4,  2],\n",
      "        [ 0,  0,  0,  0,  0,  0,  8, 10, 10,  2, 10,  2, 11,  5,  1, 12,  6, 11,\n",
      "          8, 10,  2, 12,  5,  1, 10,  7,  6, 11, 10,  8,  4, 11,  7, 10,  1,  2,\n",
      "         10, 11,  4,  4,  2],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10, 10,  2,  8,\n",
      "         10, 12,  1,  1, 10, 10,  8,  4, 11, 10, 10,  2, 11, 11, 10, 12,  6, 10,\n",
      "         10, 10, 12,  3,  2],\n",
      "        [ 0,  0,  0,  0, 12,  1, 10, 11, 11,  4,  5, 12,  8, 10, 12,  2,  8,  1,\n",
      "         10, 11, 12, 10,  7, 10, 10, 10, 12, 10,  2,  8, 10,  1,  4,  7, 11,  1,\n",
      "         10,  7,  8, 10,  2],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  8, 10, 10, 11,  2,  2,  8,\n",
      "         11,  8,  1, 10,  2]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(len(X_final))\n",
    "print(len(Y_final))\n",
    "print(X_final[0].shape)\n",
    "print(Y_final[0].shape)\n",
    "print(X_final[0][0].shape)\n",
    "print(Y_final[0][0].shape)\n",
    "print(X_final[1].shape)\n",
    "print(Y_final[1].shape)\n",
    "print(X_final[0])\n",
    "print(Y_final[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([59449, 300])\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE  = 300  # each word in word2vec model is represented using a 300 dimensional vector\n",
    "VOCABULARY_SIZE = num_words + 1\n",
    "\n",
    "with open('./embedding_weights.pickle', 'rb') as file:\n",
    "    embedding_weights = pickle.load(file)\n",
    "\n",
    "print(embedding_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "\n",
    "    num_embeddings, embedding_dim = weights_matrix.size()\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "    \n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTagger_encoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, target_size,batch_size):\n",
    "        super(RNNTagger_encoder, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.target_size = target_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.word_embeddings, vocab_size, embedding_dim = create_emb_layer(embedding_weights, True)\n",
    "        #self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first = True)\n",
    "        #self.hidden2tag = nn.Linear(hidden_dim, target_size)\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        #print(\"ENTERING ENCODER\")\n",
    "\n",
    "        #Input shape: [len(sentence)]\n",
    "        embeds = self.word_embeddings(sentence)  \n",
    "        #embeds shape: [len(sentence), embdeddin_dim]\n",
    "  \n",
    "        \n",
    "        #input shape: [len(sentence),1,embedding_dim] (L,N,Hin​) when batch_first=False)\n",
    "        rnn_out, hidden_state_out = self.rnn(embeds)  \n",
    "        #rnn_out shape: [len(sentence),1,hidden_dim] \n",
    "        #hiddsen_state_out shape: [1,1,hidden_shape]  The hidden state corresponding to last time step\n",
    "\n",
    "        #print(\"LEAVING ENCODER\")\n",
    "        \n",
    "        return rnn_out,hidden_state_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTagger_decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, target_size,batch_size):\n",
    "        super(RNNTagger_decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.target_size = target_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.word_embeddings, vocab_size, embedding_dim = create_emb_layer(embedding_weights, True)\n",
    "        #self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first = True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, target_size)\n",
    "        \n",
    "    def forward(self, sentence,hidden):\n",
    "        #print(\"ENTERING DECODER\")\n",
    "\n",
    "\n",
    "        #Input shape: [len(sentence)]  --torch.Size([8, 1])\n",
    "        #Input shape: [batch_size,max_length in that batch]\n",
    "        embeds = self.word_embeddings(sentence)  \n",
    "        #print(\"after embedding:\", embeds.shape) #--torch.Size([8, 1, 300])\n",
    "        #embeds shape: [len(sentence), embdeddin_dim] -- torch.Size([batch_Size, max_length_in_that_batch, embedding_dim])\n",
    "   \n",
    "        \n",
    "        #input shape: [len(sentence),1,embedding_dim] (L,N,Hin​) when batch_first=False)\n",
    "        #input deocder shape: torch.Size([1, 1, 64]\n",
    "        rnn_out, hidden_state_out = self.rnn(embeds,hidden) \n",
    "        #print(\"after rnn:\", rnn_out.shape , hidden_state_out.shape) #torch.Size([8, 1, 64]),torch.Size([1, 8, 64])\n",
    "\n",
    "\n",
    "        #input shape: [len(sentence),hidden_dim]  -- torch.Size([8, 1, 64])\n",
    "        tag_space = self.hidden2tag(rnn_out)\n",
    "        #tag_shape : (len(sentence),target_size) --torch.Size([8, 1, 13])\n",
    "        \n",
    "        tag_scores = F.log_softmax(tag_space, dim=2) \n",
    "        #print(\"DONE SOFTMAX:\", tag_scores.shape) #--torch.Size([8, 1, 13])\n",
    "\n",
    "        #print(\"LEAVING DECODER\")\n",
    "        return tag_scores,hidden_state_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTagger_seq2seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, target_size,batch_size,device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.target_size =  target_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        \n",
    "    def forward(self, sentence, gt_pos_tags):\n",
    "        \n",
    "\n",
    "        outputs = torch.zeros(self.batch_size,sentence.shape[1],self.target_size).to(self.device)\n",
    "        outputs = outputs.transpose(1,2)\n",
    "        #print(\"before encoder:\", outputs.shape) #--torch.Size([8, 13, 45])\n",
    "        \n",
    "        #print(\"for encoder input:\" , sentence.shape)  --torch.Size([8, 45])\n",
    "        encoder_out, hidden = self.encoder(sentence)\n",
    "        #print(\"DONE ENCODER:\", encoder_out.shape , hidden.shape) --torch.Size([8, 45, 64]) and torch.Size([1, 8, 64])\n",
    "        \n",
    "\n",
    "        index = 0\n",
    "\n",
    "        sentence_col_time = sentence.transpose(0,1)\n",
    "        #print(\"before for loop:\", sentence_col_time.shape) --torch.Size([45, 8])\n",
    "\n",
    "        for token in sentence_col_time:\n",
    "            #print(\"entering for loop\", token.shape) --torch.Size([8])\n",
    "            \n",
    "            token = token.unsqueeze(1)\n",
    "            #print(\"after unsqueeze:\", token.shape) --torch.Size([8, 1])\n",
    "            \n",
    "            token = token.to(device = self.device)\n",
    "\n",
    " \n",
    "            output, hidden = self.decoder(token, hidden)\n",
    "            #print(\"output shape:\", output.shape) --torch.Size([1, target_size])  # 8 1 13\n",
    "            #print(\"hidden shape:\", hidden.shape) --torch.Size([1, 1, hidden_dim])\n",
    "            \n",
    "    \n",
    "            #print(\"output shape before:\" , output.shape) --torch.Size([8, 1, 13])\n",
    "            output = output.squeeze(1)\n",
    "            #print(\"output shape after:\", output.shape) --torch.Size([8, 13])\n",
    "            outputs[:,:,index] = output\n",
    "            index += 1\n",
    "\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model,loss_function,optimizer,device,X,Y):\n",
    "    train_length = len(X)\n",
    "    epoch_train_loss = 0 \n",
    "   \n",
    "    model.train()\n",
    "    for i in tqdm(range(train_length)):\n",
    "        sentence_batch = X[i]\n",
    "        tags_batch = Y[i]\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        tag_scores = model(sentence_batch,tags_batch)\n",
    "        #--torch.Size([8, 13, 45])\n",
    "\n",
    "        loss = loss_function(tag_scores, tags_batch)\n",
    "        epoch_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model, epoch_train_loss/train_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop(model,loss_function,device,X,Y):\n",
    "    val_length = len(X)\n",
    "    epoch_val_loss = 0 \n",
    "\n",
    "    for i in tqdm(range(val_length)):\n",
    "        sentence_batch = X[i]\n",
    "        tags_batch = Y[i]\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        tag_scores = model(sentence_batch,tags_batch)   \n",
    "\n",
    "        loss = loss_function(tag_scores, tags_batch)\n",
    "        epoch_val_loss += loss.item()\n",
    "     \n",
    "    \n",
    "    return epoch_val_loss/val_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_DIM = 64\n",
    "batch_size = 8\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "enc = RNNTagger_encoder(HIDDEN_DIM, len(unique_tags_dict.keys())+1,batch_size)\n",
    "dec = RNNTagger_decoder(HIDDEN_DIM,len(unique_tags_dict.keys())+1,batch_size)\n",
    "model = RNNTagger_seq2seq(enc, dec, len(unique_tags_dict.keys())+1,batch_size,device).to(device=device)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.1\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_final, Y_final, test_size=TEST_SIZE, random_state=4)\n",
    "\n",
    "VALID_SIZE = 0.15\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size=VALID_SIZE, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6904/6904 [03:11<00:00, 36.06it/s]\n",
      "100%|██████████| 1219/1219 [00:14<00:00, 82.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 0, training loss: 0.4572828239378188, validation loss: 0.3427211894753822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6904/6904 [03:14<00:00, 35.52it/s]\n",
      "100%|██████████| 1219/1219 [00:14<00:00, 84.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 1, training loss: 0.30026187022191797, validation loss: 0.2809552652081375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    model , train_loss = train_loop(model,loss_function,optimizer,device,X_train,Y_train)\n",
    "    val_loss = validation_loop(model,loss_function,device,X_validation,Y_validation)\n",
    "    print(\"For epoch {}, training loss: {}, validation loss: {}\".format(epoch, train_loss, val_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
