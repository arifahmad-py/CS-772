{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import treebank\n",
    "from nltk.corpus import conll2000\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "treebank_corpus = treebank.tagged_sents(tagset='universal')\n",
    "brown_corpus = brown.tagged_sents(tagset='universal')\n",
    "conll_corpus = conll2000.tagged_sents(tagset='universal')\n",
    "tagged_sentences = treebank_corpus + brown_corpus + conll_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NOUN'),\n",
       " ('Vinken', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('61', 'NUM'),\n",
       " ('years', 'NOUN'),\n",
       " ('old', 'ADJ'),\n",
       " (',', '.'),\n",
       " ('will', 'VERB'),\n",
       " ('join', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('board', 'NOUN'),\n",
       " ('as', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('nonexecutive', 'ADJ'),\n",
       " ('director', 'NOUN'),\n",
       " ('Nov.', 'NOUN'),\n",
       " ('29', 'NUM'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # store input sequence\n",
    "Y = [] # store output sequence\n",
    "\n",
    "for sentence in tagged_sentences:\n",
    "    X_sentence = []\n",
    "    Y_sentence = []\n",
    "    for entity in sentence:         \n",
    "        X_sentence.append(entity[0])  # entity[0] contains the word\n",
    "        Y_sentence.append(entity[1])  # entity[1] contains corresponding tag\n",
    "        \n",
    "    X.append(X_sentence)\n",
    "    Y.append(Y_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59448\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "num_words = len(set([word.lower() for sentence in X for word in sentence]))\n",
    "num_tags   = len(set([word.lower() for sentence in Y for word in sentence]))\n",
    "print(num_words)\n",
    "print(num_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verb': 1, 'pron': 2, 'prt': 3, 'adv': 4, 'num': 5, 'det': 6, '.': 7, 'noun': 8, 'adp': 9, 'adj': 10, 'conj': 11, 'x': 12}\n"
     ]
    }
   ],
   "source": [
    "unique_tags = list(set([word.lower() for sentence in Y for word in sentence]))\n",
    "unique_tags_dict = {}\n",
    "index = 1\n",
    "for tag in unique_tags:\n",
    "    unique_tags_dict[tag] = index \n",
    "    index += 1\n",
    "print(unique_tags_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59448\n"
     ]
    }
   ],
   "source": [
    "unique_words = list(set([word.lower() for sentence in X for word in sentence]))\n",
    "unique_words_dict = {}\n",
    "index = 1\n",
    "for word in unique_words:\n",
    "    unique_words_dict[word] = index \n",
    "    index += 1\n",
    "print(len(unique_words_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59448\n"
     ]
    }
   ],
   "source": [
    "values = []\n",
    "for i in unique_words_dict.keys():\n",
    "    values.append(unique_words_dict[i])\n",
    "\n",
    "print(max(values))\n",
    "max_value_dict = max(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence_sentence(seq, to_ix):\n",
    "    \"\"\"Input: takes in a list of words, and a dictionary containing the index of the words\n",
    "    Output: a tensor containing the indexes of the word\"\"\"\n",
    "    idxs = [to_ix[w.lower()] for w in seq]\n",
    "    random_index = random.randint(0,len(idxs)-1)\n",
    "    idxs[random_index] = max_value_dict + 1\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence_tags(seq, to_ix):\n",
    "    \"\"\"Input: takes in a list of words, and a dictionary containing the index of the words\n",
    "    Output: a tensor containing the indexes of the word\"\"\"\n",
    "    idxs = [to_ix[w.lower()] for w in seq]\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "def split(list_a, batch_size):\n",
    "\n",
    "  for i in range(0, len(list_a), batch_size):\n",
    "    yield list_a[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "X_batches = list(split(X, batch_size))\n",
    "Y_batches = list(split(Y,batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batches_padded = []\n",
    "Y_batches_padded = []\n",
    "max_length_list = []\n",
    "\n",
    "for b_s,b_t in zip(X_batches,Y_batches):\n",
    "    max_seq_length = 0\n",
    "    for sentence in b_s:\n",
    "        if len(sentence) > max_seq_length:\n",
    "            max_seq_length = len(sentence)\n",
    "    \n",
    "    sen_encoded = []\n",
    "    tag_encoded = []\n",
    "    for sentence,tags in zip(b_s,b_t):\n",
    "        sen_encoded.append(prepare_sequence_sentence(sentence, unique_words_dict))\n",
    "        tag_encoded.append(prepare_sequence_tags(tags, unique_tags_dict))\n",
    "    \n",
    "    X_batches_padded.append(pad_sequences(sen_encoded, maxlen=max_seq_length, padding=\"pre\", truncating=\"post\"))\n",
    "    Y_batches_padded.append(pad_sequences(tag_encoded, maxlen=max_seq_length, padding=\"pre\", truncating=\"post\"))\n",
    "    max_length_list.append(max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9026\n",
      "9026\n",
      "9026\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_batches_padded))\n",
    "print(len(X_batches_padded))\n",
    "print(len(max_length_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(Y_batches_padded[0]))\n",
    "len(X_batches_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8\n",
      "   8  7  5  8 10  7  1  1  6  8  9  6 10  8  8  5  7]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  8  8  1  8  9  8  8  7  6  8  1  8  7]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  8  7  5  8 10 11 10  8  9\n",
      "   8  8  8  8  7  1  1 12  6 10  8  9  6 10 10  8  7]\n",
      " [ 6  8  9  8  4  1 12 12  3  1  8  8  8  1  1  6 10  8  9  8  8  9  6  8\n",
      "   9  8  1 12  3  2  4  9  5  8  9  7  8  1 12 12  7]\n",
      " [ 0  0  0  0  0  0  6  8  8  7  8  7  1  4 10  9  2  1  6  8  7  9  4 10\n",
      "   8  3  2  1  8  6 12  1  3  8 10  7  8  1 12 12  7]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  8  7  6  8  9 10 10  8  8\n",
      "   6 12  1  8  8  7  1  1  8  9  2  8  8  8  9  5  7]\n",
      " [ 0  0  0  0  9 10  8  1  1 12  4  9  6  8  9  7  6 10  8  1  9  8  3  8\n",
      "   8  8  9  8  7  6  8 10 12  3  1 10  8  3  6  8  7]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  6  8  8  1  7  7  6  1  6 10  8  7]]\n",
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0 39826\n",
      "  41400 24506 59449 39157  1818 24506 49182 19737 32796 59053 37061  2553\n",
      "  10343 52855  7530 10848 56487]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0  9036 41400 14635 59449 34756 55094 35024 24506\n",
      "  32796 56088 57142 24160 56487]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0 54981 58508 59449 18011 39157  1818 17532 15674 47910 34756\n",
      "  50426 22095 26896 31213 24506  8391 30331 57419  2553 10343 52855 34756\n",
      "  42855 53134 54938    56 56487]\n",
      " [ 2553 41810 34756  9383 46451 15423 19305 19305  1931 16990 59449 18305\n",
      "  57874  7836 31231  2553   355 15908 34756 44918 53185 44330  2553 24160\n",
      "  34756 24757 20025 19305  1931   212 29290 27600 28364 39157 21376 24506\n",
      "  43015 52704 50734 23617 56487]\n",
      " [    0     0     0     0     0     0 32796 59449 52896 24506 37192 24506\n",
      "  14635 12601  7554 46451   212 39477 32796 58642 24506 48357 14841 35023\n",
      "  12029  1931   212 15766 48765 46021 23617 55416 55207  1927 17821 24506\n",
      "  43015 46323 50734 40948 56487]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0 34661 12432 24506 32796 24858 34756 59449 34695 20282 32850\n",
      "  46021 40948 44053 29848 13419 24506 43211 32449 37192 25380 14130 54570\n",
      "  18305 57874 25380 53434 56487]\n",
      " [    0     0     0     0 35647 56194 10478 35748 52704 16778 29290 27600\n",
      "   2553 31196 21376 24506 32796 59449 50664 37559 25380 26036  6398 29952\n",
      "  24946 50529 34756 38320 24506  2553  9249 17923 19305  1931  3908 29952\n",
      "  27703  1931 32796 26267 56487]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0  2553 34661 50389 46323 24506 28326 42855\n",
      "  14635 20181 59449 51635 56487]]\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "print(Y_batches_padded[0])\n",
    "print(X_batches_padded[0])\n",
    "print(max_length_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = []\n",
    "Y_final = []\n",
    "\n",
    "for index in range(len(X_batches_padded)):\n",
    "    X_batch_tensor = torch.zeros((batch_size,max_length_list[index]),dtype = int).to(device= device)\n",
    "    Y_batch_tensor = torch.zeros((batch_size,max_length_list[index]), dtype = int).to(device = device)\n",
    "\n",
    "    count = 0\n",
    "    for x, y in zip(X_batches_padded[index],Y_batches_padded[index]):\n",
    "        X_batch_tensor[count] = torch.tensor(x).to(device = device)\n",
    "        Y_batch_tensor[count] = torch.tensor(y).to(device =device)\n",
    "        count += 1\n",
    "    \n",
    "    X_final.append(X_batch_tensor)\n",
    "    Y_final.append(Y_batch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9026\n",
      "9026\n",
      "torch.Size([8, 41])\n",
      "torch.Size([8, 41])\n",
      "torch.Size([41])\n",
      "torch.Size([41])\n",
      "torch.Size([8, 38])\n",
      "torch.Size([8, 38])\n",
      "tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0, 39826, 41400, 24506, 59449, 39157,  1818, 24506,\n",
      "         49182, 19737, 32796, 59053, 37061,  2553, 10343, 52855,  7530, 10848,\n",
      "         56487],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,  9036, 41400,\n",
      "         14635, 59449, 34756, 55094, 35024, 24506, 32796, 56088, 57142, 24160,\n",
      "         56487],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0, 54981, 58508, 59449, 18011, 39157,  1818,\n",
      "         17532, 15674, 47910, 34756, 50426, 22095, 26896, 31213, 24506,  8391,\n",
      "         30331, 57419,  2553, 10343, 52855, 34756, 42855, 53134, 54938,    56,\n",
      "         56487],\n",
      "        [ 2553, 41810, 34756,  9383, 46451, 15423, 19305, 19305,  1931, 16990,\n",
      "         59449, 18305, 57874,  7836, 31231,  2553,   355, 15908, 34756, 44918,\n",
      "         53185, 44330,  2553, 24160, 34756, 24757, 20025, 19305,  1931,   212,\n",
      "         29290, 27600, 28364, 39157, 21376, 24506, 43015, 52704, 50734, 23617,\n",
      "         56487],\n",
      "        [    0,     0,     0,     0,     0,     0, 32796, 59449, 52896, 24506,\n",
      "         37192, 24506, 14635, 12601,  7554, 46451,   212, 39477, 32796, 58642,\n",
      "         24506, 48357, 14841, 35023, 12029,  1931,   212, 15766, 48765, 46021,\n",
      "         23617, 55416, 55207,  1927, 17821, 24506, 43015, 46323, 50734, 40948,\n",
      "         56487],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0, 34661, 12432, 24506, 32796, 24858, 34756,\n",
      "         59449, 34695, 20282, 32850, 46021, 40948, 44053, 29848, 13419, 24506,\n",
      "         43211, 32449, 37192, 25380, 14130, 54570, 18305, 57874, 25380, 53434,\n",
      "         56487],\n",
      "        [    0,     0,     0,     0, 35647, 56194, 10478, 35748, 52704, 16778,\n",
      "         29290, 27600,  2553, 31196, 21376, 24506, 32796, 59449, 50664, 37559,\n",
      "         25380, 26036,  6398, 29952, 24946, 50529, 34756, 38320, 24506,  2553,\n",
      "          9249, 17923, 19305,  1931,  3908, 29952, 27703,  1931, 32796, 26267,\n",
      "         56487],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,  2553,\n",
      "         34661, 50389, 46323, 24506, 28326, 42855, 14635, 20181, 59449, 51635,\n",
      "         56487]], device='cuda:0')\n",
      "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  8,  8,  7,  5,  8, 10,  7,  1,  1,  6,  8,  9,  6,\n",
      "         10,  8,  8,  5,  7],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  8,  8,  1,  8,  9,  8,  8,  7,\n",
      "          6,  8,  1,  8,  7],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  8,  8,  7,  5,\n",
      "          8, 10, 11, 10,  8,  9,  8,  8,  8,  8,  7,  1,  1, 12,  6, 10,  8,  9,\n",
      "          6, 10, 10,  8,  7],\n",
      "        [ 6,  8,  9,  8,  4,  1, 12, 12,  3,  1,  8,  8,  8,  1,  1,  6, 10,  8,\n",
      "          9,  8,  8,  9,  6,  8,  9,  8,  1, 12,  3,  2,  4,  9,  5,  8,  9,  7,\n",
      "          8,  1, 12, 12,  7],\n",
      "        [ 0,  0,  0,  0,  0,  0,  6,  8,  8,  7,  8,  7,  1,  4, 10,  9,  2,  1,\n",
      "          6,  8,  7,  9,  4, 10,  8,  3,  2,  1,  8,  6, 12,  1,  3,  8, 10,  7,\n",
      "          8,  1, 12, 12,  7],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  8,  8,  7,  6,\n",
      "          8,  9, 10, 10,  8,  8,  6, 12,  1,  8,  8,  7,  1,  1,  8,  9,  2,  8,\n",
      "          8,  8,  9,  5,  7],\n",
      "        [ 0,  0,  0,  0,  9, 10,  8,  1,  1, 12,  4,  9,  6,  8,  9,  7,  6, 10,\n",
      "          8,  1,  9,  8,  3,  8,  8,  8,  9,  8,  7,  6,  8, 10, 12,  3,  1, 10,\n",
      "          8,  3,  6,  8,  7],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  6,  8,  8,  1,  7,  7,  6,\n",
      "          1,  6, 10,  8,  7]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(len(X_final))\n",
    "print(len(Y_final))\n",
    "print(X_final[0].shape)\n",
    "print(Y_final[0].shape)\n",
    "print(X_final[0][0].shape)\n",
    "print(Y_final[0][0].shape)\n",
    "print(X_final[1].shape)\n",
    "print(Y_final[1].shape)\n",
    "print(X_final[0])\n",
    "print(Y_final[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([59450, 300])\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE  = 300  # each word in word2vec model is represented using a 300 dimensional vector\n",
    "VOCABULARY_SIZE = num_words + 1\n",
    "\n",
    "with open('./embedding_weights.pickle', 'rb') as file:\n",
    "    embedding_weights = pickle.load(file)\n",
    "\n",
    "print(embedding_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "\n",
    "    num_embeddings, embedding_dim = weights_matrix.size()\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "    \n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTagger_encoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, target_size,batch_size):\n",
    "        super(RNNTagger_encoder, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.target_size = target_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.word_embeddings, vocab_size, embedding_dim = create_emb_layer(embedding_weights, True)\n",
    "        #self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first = True)\n",
    "        #self.hidden2tag = nn.Linear(hidden_dim, target_size)\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        #print(\"ENTERING ENCODER\")\n",
    "\n",
    "        #Input shape: [len(sentence)]\n",
    "        embeds = self.word_embeddings(sentence)  \n",
    "        #embeds shape: [len(sentence), embdeddin_dim]\n",
    "  \n",
    "        \n",
    "        #input shape: [len(sentence),1,embedding_dim] (L,N,Hin​) when batch_first=False)\n",
    "        rnn_out, hidden_state_out = self.rnn(embeds)  \n",
    "        #rnn_out shape: [len(sentence),1,hidden_dim] \n",
    "        #hiddsen_state_out shape: [1,1,hidden_shape]  The hidden state corresponding to last time step\n",
    "\n",
    "        #print(\"LEAVING ENCODER\")\n",
    "        \n",
    "        return rnn_out,hidden_state_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTagger_decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, target_size,batch_size):\n",
    "        super(RNNTagger_decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.target_size = target_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.word_embeddings, vocab_size, embedding_dim = create_emb_layer(embedding_weights, True)\n",
    "        #self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first = True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, target_size)\n",
    "        \n",
    "    def forward(self, sentence,hidden):\n",
    "        #print(\"ENTERING DECODER\")\n",
    "\n",
    "\n",
    "        #Input shape: [len(sentence)]  --torch.Size([8, 1])\n",
    "        #Input shape: [batch_size,max_length in that batch]\n",
    "        embeds = self.word_embeddings(sentence)  \n",
    "        #print(\"after embedding:\", embeds.shape) #--torch.Size([8, 1, 300])\n",
    "        #embeds shape: [len(sentence), embdeddin_dim] -- torch.Size([batch_Size, max_length_in_that_batch, embedding_dim])\n",
    "   \n",
    "        \n",
    "        #input shape: [len(sentence),1,embedding_dim] (L,N,Hin​) when batch_first=False)\n",
    "        #input deocder shape: torch.Size([1, 1, 64]\n",
    "        rnn_out, hidden_state_out = self.rnn(embeds,hidden) \n",
    "        #print(\"after rnn:\", rnn_out.shape , hidden_state_out.shape) #torch.Size([8, 1, 64]),torch.Size([1, 8, 64])\n",
    "\n",
    "\n",
    "        #input shape: [len(sentence),hidden_dim]  -- torch.Size([8, 1, 64])\n",
    "        tag_space = self.hidden2tag(rnn_out)\n",
    "        #tag_shape : (len(sentence),target_size) --torch.Size([8, 1, 13])\n",
    "        \n",
    "        tag_scores = F.log_softmax(tag_space, dim=2) \n",
    "        #print(\"DONE SOFTMAX:\", tag_scores.shape) #--torch.Size([8, 1, 13])\n",
    "\n",
    "        #print(\"LEAVING DECODER\")\n",
    "        return tag_scores,hidden_state_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTagger_seq2seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, target_size,batch_size,device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.target_size =  target_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        \n",
    "    def forward(self, sentence, gt_pos_tags):\n",
    "        \n",
    "\n",
    "        outputs = torch.zeros(self.batch_size,sentence.shape[1],self.target_size).to(self.device)\n",
    "        outputs = outputs.transpose(1,2)\n",
    "        #print(\"before encoder:\", outputs.shape) #--torch.Size([8, 13, 45])\n",
    "        \n",
    "        #print(\"for encoder input:\" , sentence.shape)  --torch.Size([8, 45])\n",
    "        encoder_out, hidden = self.encoder(sentence)\n",
    "        #print(\"DONE ENCODER:\", encoder_out.shape , hidden.shape) --torch.Size([8, 45, 64]) and torch.Size([1, 8, 64])\n",
    "        \n",
    "\n",
    "        index = 0\n",
    "\n",
    "        sentence_col_time = sentence.transpose(0,1)\n",
    "        #print(\"before for loop:\", sentence_col_time.shape) --torch.Size([45, 8])\n",
    "\n",
    "        for token in sentence_col_time:\n",
    "            #print(\"entering for loop\", token.shape) --torch.Size([8])\n",
    "            \n",
    "            token = token.unsqueeze(1)\n",
    "            #print(\"after unsqueeze:\", token.shape) --torch.Size([8, 1])\n",
    "            \n",
    "            token = token.to(device = self.device)\n",
    "\n",
    " \n",
    "            output, hidden = self.decoder(token, hidden)\n",
    "            #print(\"output shape:\", output.shape) --torch.Size([1, target_size])  # 8 1 13\n",
    "            #print(\"hidden shape:\", hidden.shape) --torch.Size([1, 1, hidden_dim])\n",
    "            \n",
    "    \n",
    "            #print(\"output shape before:\" , output.shape) --torch.Size([8, 1, 13])\n",
    "            output = output.squeeze(1)\n",
    "            #print(\"output shape after:\", output.shape) --torch.Size([8, 13])\n",
    "            outputs[:,:,index] = output\n",
    "            index += 1\n",
    "\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model,loss_function,optimizer,device,X,Y):\n",
    "    train_length = len(X)\n",
    "    epoch_train_loss = 0 \n",
    "   \n",
    "    model.train()\n",
    "    for i in tqdm(range(train_length)):\n",
    "        sentence_batch = X[i]\n",
    "        tags_batch = Y[i]\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        tag_scores = model(sentence_batch,tags_batch)\n",
    "        #--torch.Size([8, 13, 45])\n",
    "\n",
    "        loss = loss_function(tag_scores, tags_batch)\n",
    "        epoch_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model, epoch_train_loss/train_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop(model,loss_function,device,X,Y):\n",
    "    val_length = len(X)\n",
    "    epoch_val_loss = 0 \n",
    "\n",
    "    for i in tqdm(range(val_length)):\n",
    "        sentence_batch = X[i]\n",
    "        tags_batch = Y[i]\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        tag_scores = model(sentence_batch,tags_batch)   \n",
    "\n",
    "        loss = loss_function(tag_scores, tags_batch)\n",
    "        epoch_val_loss += loss.item()\n",
    "     \n",
    "    \n",
    "    return epoch_val_loss/val_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_DIM = 64\n",
    "batch_size = 8\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "enc = RNNTagger_encoder(HIDDEN_DIM, len(unique_tags_dict.keys())+1,batch_size)\n",
    "dec = RNNTagger_decoder(HIDDEN_DIM,len(unique_tags_dict.keys())+1,batch_size)\n",
    "model = RNNTagger_seq2seq(enc, dec, len(unique_tags_dict.keys())+1,batch_size,device).to(device=device)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.1\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_final, Y_final, test_size=TEST_SIZE, random_state=4)\n",
    "\n",
    "VALID_SIZE = 0.15\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size=VALID_SIZE, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6904/6904 [08:03<00:00, 14.28it/s]\n",
      "100%|██████████| 1219/1219 [00:35<00:00, 34.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 0, training loss: 0.47985887257565735, validation loss: 0.37412444441606024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6904/6904 [03:54<00:00, 29.44it/s]\n",
      "100%|██████████| 1219/1219 [00:14<00:00, 82.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 1, training loss: 0.3413503014343345, validation loss: 0.3197310728137859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    model , train_loss = train_loop(model,loss_function,optimizer,device,X_train,Y_train)\n",
    "    val_loss = validation_loop(model,loss_function,device,X_validation,Y_validation)\n",
    "    print(\"For epoch {}, training loss: {}, validation loss: {}\".format(epoch, train_loss, val_loss))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEMO CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_TESTsequence_sentence(seq, to_ix):\n",
    "    values = []\n",
    "    for i in to_ix.keys():\n",
    "        values.append(to_ix[i])\n",
    "    \n",
    "    max_value_dict = max(values)\n",
    "    \n",
    "    idxs = []\n",
    "\n",
    "    for w in seq:\n",
    "        if w.lower() in to_ix.keys():\n",
    "            idxs.append(to_ix[w.lower()])\n",
    "        else:\n",
    "            idxs.append(max_value_dict+1)\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'verb',\n",
       " 2: 'pron',\n",
       " 3: 'prt',\n",
       " 4: 'adv',\n",
       " 5: 'num',\n",
       " 6: 'det',\n",
       " 7: '.',\n",
       " 8: 'noun',\n",
       " 9: 'adp',\n",
       " 10: 'adj',\n",
       " 11: 'conj',\n",
       " 12: 'x'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_tags = {}\n",
    "for tag in unique_tags_dict:\n",
    "    index_to_tags[unique_tags_dict[tag]] = tag \n",
    "index_to_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bottle', 'is', '5', 'years', 'old', ',', 'non', 'executive', 'director', 'of', 'CSK']\n",
      "[5554, 14635, 18538, 39157, 1818, 24506, 26122, 23295, 52855, 34756, 59449]\n",
      "torch.Size([8, 11])\n",
      "torch.Size([8, 13, 11])\n",
      "torch.Size([8, 13])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mprint\u001b[39m(output[:,:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m predicted_tag,word \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(tag_index,tokenized_seq):\n\u001b[1;32m---> 19\u001b[0m     predicted_tag \u001b[39m=\u001b[39m predicted_tag\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m     20\u001b[0m     predicted_tag \u001b[39m=\u001b[39m index_to_tags[predicted_tag]\n\u001b[0;32m     21\u001b[0m     \u001b[39mprint\u001b[39m(word, predicted_tag)\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text = \"bottle is 5 years old, non executive director of CSK\"\n",
    "tokenized_seq = word_tokenize(text)\n",
    "print(tokenized_seq)\n",
    "\n",
    "tokens= prepare_TESTsequence_sentence(tokenized_seq,unique_words_dict)\n",
    "print(tokens) \n",
    "\n",
    "tokens = torch.tensor(tokens).to(device = device)\n",
    "tokens = tokens.unsqueeze(0)\n",
    "sample_gt = torch.zeros(1,len(tokens)).to(device=device)\n",
    "output = model(tokens,sample_gt)\n",
    "output = output.squeeze(0)\n",
    "tag_index = torch.argmax(output,dim=1)\n",
    "print(tag_index.shape)\n",
    "print(output.shape)\n",
    "print(output[:,:,0].shape)\n",
    "for predicted_tag,word in zip(tag_index,tokenized_seq):\n",
    "    predicted_tag = predicted_tag.item()\n",
    "    predicted_tag = index_to_tags[predicted_tag]\n",
    "    print(word, predicted_tag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
