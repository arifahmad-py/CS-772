{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\sem8\\CS772\\A2_Part1\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import treebank\n",
    "from nltk.corpus import conll2000\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "treebank_corpus = treebank.tagged_sents(tagset='universal')\n",
    "brown_corpus = brown.tagged_sents(tagset='universal')\n",
    "conll_corpus = conll2000.tagged_sents(tagset='universal')\n",
    "tagged_sentences = treebank_corpus + brown_corpus + conll_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NOUN'),\n",
       " ('Vinken', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('61', 'NUM'),\n",
       " ('years', 'NOUN'),\n",
       " ('old', 'ADJ'),\n",
       " (',', '.'),\n",
       " ('will', 'VERB'),\n",
       " ('join', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('board', 'NOUN'),\n",
       " ('as', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('nonexecutive', 'ADJ'),\n",
       " ('director', 'NOUN'),\n",
       " ('Nov.', 'NOUN'),\n",
       " ('29', 'NUM'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # store input sequence\n",
    "Y = [] # store output sequence\n",
    "\n",
    "for sentence in tagged_sentences:\n",
    "    X_sentence = []\n",
    "    Y_sentence = []\n",
    "    for entity in sentence:         \n",
    "        X_sentence.append(entity[0])  # entity[0] contains the word\n",
    "        Y_sentence.append(entity[1])  # entity[1] contains corresponding tag\n",
    "        \n",
    "    X.append(X_sentence)\n",
    "    Y.append(Y_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59448\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "num_words = len(set([word.lower() for sentence in X for word in sentence]))\n",
    "num_tags   = len(set([word.lower() for sentence in Y for word in sentence]))\n",
    "print(num_words)\n",
    "print(num_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verb': 1, 'adp': 2, 'x': 3, 'prt': 4, 'adv': 5, 'adj': 6, 'conj': 7, 'noun': 8, 'det': 9, 'pron': 10, '.': 11, 'num': 12}\n"
     ]
    }
   ],
   "source": [
    "unique_tags = list(set([word.lower() for sentence in Y for word in sentence]))\n",
    "unique_tags_dict = {}\n",
    "index = 1\n",
    "for tag in unique_tags:\n",
    "    unique_tags_dict[tag] = index \n",
    "    index += 1\n",
    "print(unique_tags_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59448\n"
     ]
    }
   ],
   "source": [
    "unique_words = list(set([word.lower() for sentence in X for word in sentence]))\n",
    "unique_words_dict = {}\n",
    "index = 1\n",
    "for word in unique_words:\n",
    "    unique_words_dict[word] = index \n",
    "    index += 1\n",
    "print(len(unique_words_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59448\n"
     ]
    }
   ],
   "source": [
    "values = []\n",
    "for i in unique_words_dict.keys():\n",
    "    values.append(unique_words_dict[i])\n",
    "\n",
    "print(max(values))\n",
    "max_value_dict = max(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence_sentence(seq, to_ix):\n",
    "    \"\"\"Input: takes in a list of words, and a dictionary containing the index of the words\n",
    "    Output: a tensor containing the indexes of the word\"\"\"\n",
    "    idxs = [to_ix[w.lower()] for w in seq]\n",
    "    random_index = random.randint(0,len(idxs)-1)\n",
    "    idxs[random_index] = max_value_dict + 1\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence_tags(seq, to_ix):\n",
    "    \"\"\"Input: takes in a list of words, and a dictionary containing the index of the words\n",
    "    Output: a tensor containing the indexes of the word\"\"\"\n",
    "    idxs = [to_ix[w.lower()] for w in seq]\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "def split(list_a, batch_size):\n",
    "\n",
    "  for i in range(0, len(list_a), batch_size):\n",
    "    yield list_a[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "X_batches = list(split(X, batch_size))\n",
    "Y_batches = list(split(Y,batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batches_padded = []\n",
    "Y_batches_padded = []\n",
    "max_length_list = []\n",
    "\n",
    "for b_s,b_t in zip(X_batches,Y_batches):\n",
    "    max_seq_length = 0\n",
    "    for sentence in b_s:\n",
    "        if len(sentence) > max_seq_length:\n",
    "            max_seq_length = len(sentence)\n",
    "    \n",
    "    sen_encoded = []\n",
    "    tag_encoded = []\n",
    "    for sentence,tags in zip(b_s,b_t):\n",
    "        sen_encoded.append(prepare_sequence_sentence(sentence, unique_words_dict))\n",
    "        tag_encoded.append(prepare_sequence_tags(tags, unique_tags_dict))\n",
    "    \n",
    "    X_batches_padded.append(pad_sequences(sen_encoded, maxlen=max_seq_length, padding=\"pre\", truncating=\"post\"))\n",
    "    Y_batches_padded.append(pad_sequences(tag_encoded, maxlen=max_seq_length, padding=\"pre\", truncating=\"post\"))\n",
    "    max_length_list.append(max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9026\n",
      "9026\n",
      "9026\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_batches_padded))\n",
    "print(len(X_batches_padded))\n",
    "print(len(max_length_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(Y_batches_padded[0]))\n",
    "len(X_batches_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8\n",
      "   8 11 12  8  6 11  1  1  9  8  2  9  6  8  8 12 11]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  8  8  1  8  2  8  8 11  9  8  1  8 11]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  8 11 12  8  6  7  6  8  2\n",
      "   8  8  8  8 11  1  1  3  9  6  8  2  9  6  6  8 11]\n",
      " [ 9  8  2  8  5  1  3  3  4  1  8  8  8  1  1  9  6  8  2  8  8  2  9  8\n",
      "   2  8  1  3  4 10  5  2 12  8  2 11  8  1  3  3 11]\n",
      " [ 0  0  0  0  0  0  9  8  8 11  8 11  1  5  6  2 10  1  9  8 11  2  5  6\n",
      "   8  4 10  1  8  9  3  1  4  8  6 11  8  1  3  3 11]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  8 11  9  8  2  6  6  8  8\n",
      "   9  3  1  8  8 11  1  1  8  2 10  8  8  8  2 12 11]\n",
      " [ 0  0  0  0  2  6  8  1  1  3  5  2  9  8  2 11  9  6  8  1  2  8  4  8\n",
      "   8  8  2  8 11  9  8  6  3  4  1  6  8  4  9  8 11]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  9  8  8  1 11 11  9  1  9  6  8 11]]\n",
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0 57964\n",
      "   8588 34315 16155 13742 52999 34315 46184 59449 39100 27013 56661 28912\n",
      "  29965 21093 44882 11073 36267]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0 41365 59449  5291  3226 23101 26292 31169 34315\n",
      "  39100  6206 26794 52293 36267]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0 30272 18292 34315  4336 13742 52999  1307  4896  3226 23101\n",
      "   4641 53194 15698 46240 59449 23910 13985 23988 28912 29965 21093 23101\n",
      "  48622 19061  9139  3333 36267]\n",
      " [28912 57886 23101 44476  8953 11239 52476 52476 57063 50713  1468 59449\n",
      "  58573  4165 20044 28912 48876 58108 23101 35417 54566 13521 28912 52293\n",
      "  23101 21437 21644 52476 57063 36573 50012 14183  1578 13742  4801 34315\n",
      "  18388  8775 36314 18146 36267]\n",
      " [    0     0     0     0     0     0 39100 44476 43388 34315 12981 34315\n",
      "   5291 35299 52034  8953 36573 23033 39100   268 34315 41256 31585 10769\n",
      "  43702 57063 36573 13484 31372  2737 59449 43354 19812 21585 50869 34315\n",
      "  18388 31051 36314 37784 36267]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0   558 59449 34315 39100 32364 23101 20076 17702 48390 18006\n",
      "   2737 37784  9857  1468 56413 34315 47182 11013 12981  3270 55789 16968\n",
      "  19166 58573  3270 31317 36267]\n",
      " [    0     0     0     0 11151  6752 19192 48401  8775 56533 50012 14183\n",
      "  28912 49542  4801 34315 39100 59449 57162 10279  3270 18164 27105 20076\n",
      "  45340 36954 23101 19269 34315 28912 50773 35480 52476 57063  7138 20076\n",
      "    225 57063 39100 11025 36267]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0 28912   558 22902 31051 34315  3150 48622\n",
      "   5291 10408 59449 40954 36267]]\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "print(Y_batches_padded[0])\n",
    "print(X_batches_padded[0])\n",
    "print(max_length_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = []\n",
    "Y_final = []\n",
    "\n",
    "for index in range(len(X_batches_padded)):\n",
    "    X_batch_tensor = torch.zeros((batch_size,max_length_list[index]),dtype = int).to(device= device)\n",
    "    Y_batch_tensor = torch.zeros((batch_size,max_length_list[index]), dtype = int).to(device = device)\n",
    "\n",
    "    count = 0\n",
    "    for x, y in zip(X_batches_padded[index],Y_batches_padded[index]):\n",
    "        X_batch_tensor[count] = torch.tensor(x).to(device = device)\n",
    "        Y_batch_tensor[count] = torch.tensor(y).to(device =device)\n",
    "        count += 1\n",
    "    \n",
    "    X_final.append(X_batch_tensor)\n",
    "    Y_final.append(Y_batch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9026\n",
      "9026\n",
      "torch.Size([8, 41])\n",
      "torch.Size([8, 41])\n",
      "torch.Size([41])\n",
      "torch.Size([41])\n",
      "torch.Size([8, 38])\n",
      "torch.Size([8, 38])\n",
      "tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0, 57964,  8588, 34315, 16155, 13742, 52999, 34315,\n",
      "         46184, 59449, 39100, 27013, 56661, 28912, 29965, 21093, 44882, 11073,\n",
      "         36267],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0, 41365, 59449,\n",
      "          5291,  3226, 23101, 26292, 31169, 34315, 39100,  6206, 26794, 52293,\n",
      "         36267],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0, 30272, 18292, 34315,  4336, 13742, 52999,\n",
      "          1307,  4896,  3226, 23101,  4641, 53194, 15698, 46240, 59449, 23910,\n",
      "         13985, 23988, 28912, 29965, 21093, 23101, 48622, 19061,  9139,  3333,\n",
      "         36267],\n",
      "        [28912, 57886, 23101, 44476,  8953, 11239, 52476, 52476, 57063, 50713,\n",
      "          1468, 59449, 58573,  4165, 20044, 28912, 48876, 58108, 23101, 35417,\n",
      "         54566, 13521, 28912, 52293, 23101, 21437, 21644, 52476, 57063, 36573,\n",
      "         50012, 14183,  1578, 13742,  4801, 34315, 18388,  8775, 36314, 18146,\n",
      "         36267],\n",
      "        [    0,     0,     0,     0,     0,     0, 39100, 44476, 43388, 34315,\n",
      "         12981, 34315,  5291, 35299, 52034,  8953, 36573, 23033, 39100,   268,\n",
      "         34315, 41256, 31585, 10769, 43702, 57063, 36573, 13484, 31372,  2737,\n",
      "         59449, 43354, 19812, 21585, 50869, 34315, 18388, 31051, 36314, 37784,\n",
      "         36267],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,   558, 59449, 34315, 39100, 32364, 23101,\n",
      "         20076, 17702, 48390, 18006,  2737, 37784,  9857,  1468, 56413, 34315,\n",
      "         47182, 11013, 12981,  3270, 55789, 16968, 19166, 58573,  3270, 31317,\n",
      "         36267],\n",
      "        [    0,     0,     0,     0, 11151,  6752, 19192, 48401,  8775, 56533,\n",
      "         50012, 14183, 28912, 49542,  4801, 34315, 39100, 59449, 57162, 10279,\n",
      "          3270, 18164, 27105, 20076, 45340, 36954, 23101, 19269, 34315, 28912,\n",
      "         50773, 35480, 52476, 57063,  7138, 20076,   225, 57063, 39100, 11025,\n",
      "         36267],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0, 28912,\n",
      "           558, 22902, 31051, 34315,  3150, 48622,  5291, 10408, 59449, 40954,\n",
      "         36267]], device='cuda:0')\n",
      "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  8,  8, 11, 12,  8,  6, 11,  1,  1,  9,  8,  2,  9,\n",
      "          6,  8,  8, 12, 11],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  8,  8,  1,  8,  2,  8,  8, 11,\n",
      "          9,  8,  1,  8, 11],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  8,  8, 11, 12,\n",
      "          8,  6,  7,  6,  8,  2,  8,  8,  8,  8, 11,  1,  1,  3,  9,  6,  8,  2,\n",
      "          9,  6,  6,  8, 11],\n",
      "        [ 9,  8,  2,  8,  5,  1,  3,  3,  4,  1,  8,  8,  8,  1,  1,  9,  6,  8,\n",
      "          2,  8,  8,  2,  9,  8,  2,  8,  1,  3,  4, 10,  5,  2, 12,  8,  2, 11,\n",
      "          8,  1,  3,  3, 11],\n",
      "        [ 0,  0,  0,  0,  0,  0,  9,  8,  8, 11,  8, 11,  1,  5,  6,  2, 10,  1,\n",
      "          9,  8, 11,  2,  5,  6,  8,  4, 10,  1,  8,  9,  3,  1,  4,  8,  6, 11,\n",
      "          8,  1,  3,  3, 11],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  8,  8, 11,  9,\n",
      "          8,  2,  6,  6,  8,  8,  9,  3,  1,  8,  8, 11,  1,  1,  8,  2, 10,  8,\n",
      "          8,  8,  2, 12, 11],\n",
      "        [ 0,  0,  0,  0,  2,  6,  8,  1,  1,  3,  5,  2,  9,  8,  2, 11,  9,  6,\n",
      "          8,  1,  2,  8,  4,  8,  8,  8,  2,  8, 11,  9,  8,  6,  3,  4,  1,  6,\n",
      "          8,  4,  9,  8, 11],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  9,  8,  8,  1, 11, 11,  9,\n",
      "          1,  9,  6,  8, 11]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(len(X_final))\n",
    "print(len(Y_final))\n",
    "print(X_final[0].shape)\n",
    "print(Y_final[0].shape)\n",
    "print(X_final[0][0].shape)\n",
    "print(Y_final[0][0].shape)\n",
    "print(X_final[1].shape)\n",
    "print(Y_final[1].shape)\n",
    "print(X_final[0])\n",
    "print(Y_final[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([59450, 300])\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE  = 300  # each word in word2vec model is represented using a 300 dimensional vector\n",
    "VOCABULARY_SIZE = num_words + 1\n",
    "\n",
    "with open('./embedding_weights.pickle', 'rb') as file:\n",
    "    embedding_weights = pickle.load(file)\n",
    "\n",
    "print(embedding_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "\n",
    "    num_embeddings, embedding_dim = weights_matrix.size()\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "    \n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTagger_encoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, target_size,batch_size):\n",
    "        super(RNNTagger_encoder, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.target_size = target_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.word_embeddings, vocab_size, embedding_dim = create_emb_layer(embedding_weights, True)\n",
    "        #self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first = True)\n",
    "        #self.hidden2tag = nn.Linear(hidden_dim, target_size)\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        #print(\"ENTERING ENCODER\")\n",
    "\n",
    "        #Input shape: [len(sentence)]\n",
    "        embeds = self.word_embeddings(sentence)  \n",
    "        #embeds shape: [len(sentence), embdeddin_dim]\n",
    "  \n",
    "        \n",
    "        #input shape: [len(sentence),1,embedding_dim] (L,N,Hin​) when batch_first=False)\n",
    "        rnn_out, hidden_state_out = self.rnn(embeds)  \n",
    "        #rnn_out shape: [len(sentence),1,hidden_dim] \n",
    "        #hiddsen_state_out shape: [1,1,hidden_shape]  The hidden state corresponding to last time step\n",
    "\n",
    "        #print(\"LEAVING ENCODER\")\n",
    "        \n",
    "        return rnn_out,hidden_state_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTagger_decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, target_size,batch_size):\n",
    "        super(RNNTagger_decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.target_size = target_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.word_embeddings, vocab_size, embedding_dim = create_emb_layer(embedding_weights, True)\n",
    "        #self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first = True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, target_size)\n",
    "        \n",
    "    def forward(self, sentence,hidden):\n",
    "        #print(\"ENTERING DECODER\")\n",
    "\n",
    "\n",
    "        #Input shape: [len(sentence)]  --torch.Size([8, 1])\n",
    "        #Input shape: [batch_size,max_length in that batch]\n",
    "        embeds = self.word_embeddings(sentence)  \n",
    "        #print(\"after embedding:\", embeds.shape) #--torch.Size([8, 1, 300])\n",
    "        #embeds shape: [len(sentence), embdeddin_dim] -- torch.Size([batch_Size, max_length_in_that_batch, embedding_dim])\n",
    "   \n",
    "        \n",
    "        #input shape: [len(sentence),1,embedding_dim] (L,N,Hin​) when batch_first=False)\n",
    "        #input deocder shape: torch.Size([1, 1, 64]\n",
    "        rnn_out, hidden_state_out = self.rnn(embeds,hidden) \n",
    "        #print(\"after rnn:\", rnn_out.shape , hidden_state_out.shape) #torch.Size([8, 1, 64]),torch.Size([1, 8, 64])\n",
    "\n",
    "\n",
    "        #input shape: [len(sentence),hidden_dim]  -- torch.Size([8, 1, 64])\n",
    "        tag_space = self.hidden2tag(rnn_out)\n",
    "        #tag_shape : (len(sentence),target_size) --torch.Size([8, 1, 13])\n",
    "        \n",
    "        tag_scores = F.log_softmax(tag_space, dim=2) \n",
    "        #print(\"DONE SOFTMAX:\", tag_scores.shape) #--torch.Size([8, 1, 13])\n",
    "\n",
    "        #print(\"LEAVING DECODER\")\n",
    "        return tag_scores,hidden_state_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTagger_seq2seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, target_size,batch_size,device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.target_size =  target_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        \n",
    "    def forward(self, sentence, gt_pos_tags):\n",
    "        \n",
    "\n",
    "        outputs = torch.zeros(self.batch_size,sentence.shape[1],self.target_size).to(self.device)\n",
    "        outputs = outputs.transpose(1,2)\n",
    "        #print(\"before encoder:\", outputs.shape) #--torch.Size([8, 13, 45])\n",
    "        \n",
    "        #print(\"for encoder input:\" , sentence.shape)  --torch.Size([8, 45])\n",
    "        encoder_out, hidden = self.encoder(sentence)\n",
    "        #print(\"DONE ENCODER:\", encoder_out.shape , hidden.shape) --torch.Size([8, 45, 64]) and torch.Size([1, 8, 64])\n",
    "        \n",
    "\n",
    "        index = 0\n",
    "\n",
    "        sentence_col_time = sentence.transpose(0,1)\n",
    "        #print(\"before for loop:\", sentence_col_time.shape) --torch.Size([45, 8])\n",
    "\n",
    "        for token in sentence_col_time:\n",
    "            #print(\"entering for loop\", token.shape) --torch.Size([8])\n",
    "            \n",
    "            token = token.unsqueeze(1)\n",
    "            #print(\"after unsqueeze:\", token.shape) --torch.Size([8, 1])\n",
    "            \n",
    "            token = token.to(device = self.device)\n",
    "\n",
    " \n",
    "            output, hidden = self.decoder(token, hidden)\n",
    "            #print(\"output shape:\", output.shape) --torch.Size([1, target_size])  # 8 1 13\n",
    "            #print(\"hidden shape:\", hidden.shape) --torch.Size([1, 1, hidden_dim])\n",
    "            \n",
    "    \n",
    "            #print(\"output shape before:\" , output.shape) --torch.Size([8, 1, 13])\n",
    "            output = output.squeeze(1)\n",
    "            #print(\"output shape after:\", output.shape) --torch.Size([8, 13])\n",
    "            outputs[:,:,index] = output\n",
    "            index += 1\n",
    "\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model,loss_function,optimizer,device,X,Y):\n",
    "    train_length = len(X)\n",
    "    epoch_train_loss = 0 \n",
    "   \n",
    "    model.train()\n",
    "    for i in tqdm(range(train_length)):\n",
    "        sentence_batch = X[i]\n",
    "        tags_batch = Y[i]\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        tag_scores = model(sentence_batch,tags_batch)\n",
    "        #--torch.Size([8, 13, 45])\n",
    "\n",
    "        loss = loss_function(tag_scores, tags_batch)\n",
    "        epoch_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model, epoch_train_loss/train_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop(model,loss_function,device,X,Y):\n",
    "    val_length = len(X)\n",
    "    epoch_val_loss = 0 \n",
    "\n",
    "    for i in tqdm(range(val_length)):\n",
    "        sentence_batch = X[i]\n",
    "        tags_batch = Y[i]\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        tag_scores = model(sentence_batch,tags_batch)   \n",
    "\n",
    "        loss = loss_function(tag_scores, tags_batch)\n",
    "        epoch_val_loss += loss.item()\n",
    "     \n",
    "    \n",
    "    return epoch_val_loss/val_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_DIM = 64\n",
    "batch_size = 8\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "enc = RNNTagger_encoder(HIDDEN_DIM, len(unique_tags_dict.keys())+1,batch_size)\n",
    "dec = RNNTagger_decoder(HIDDEN_DIM,len(unique_tags_dict.keys())+1,batch_size)\n",
    "model = RNNTagger_seq2seq(enc, dec, len(unique_tags_dict.keys())+1,batch_size,device).to(device=device)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.1\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_final, Y_final, test_size=TEST_SIZE, random_state=4)\n",
    "\n",
    "VALID_SIZE = 0.15\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size=VALID_SIZE, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6904/6904 [03:05<00:00, 37.18it/s]\n",
      "100%|██████████| 1219/1219 [00:14<00:00, 86.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 0, training loss: 0.4859058956959882, validation loss: 0.3738410583253372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6904/6904 [03:04<00:00, 37.41it/s]\n",
      "100%|██████████| 1219/1219 [00:14<00:00, 86.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch 1, training loss: 0.34101967427551505, validation loss: 0.31912644269209206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    model , train_loss = train_loop(model,loss_function,optimizer,device,X_train,Y_train)\n",
    "    val_loss = validation_loop(model,loss_function,device,X_validation,Y_validation)\n",
    "    print(\"For epoch {}, training loss: {}, validation loss: {}\".format(epoch, train_loss, val_loss))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEMO CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_TESTsequence_sentence(seq, to_ix):\n",
    "    values = []\n",
    "    for i in to_ix.keys():\n",
    "        values.append(to_ix[i])\n",
    "    \n",
    "    max_value_dict = max(values)\n",
    "    \n",
    "    idxs = []\n",
    "\n",
    "    for w in seq:\n",
    "        if w.lower() in to_ix.keys():\n",
    "            idxs.append(to_ix[w.lower()])\n",
    "        else:\n",
    "            idxs.append(max_value_dict+1)\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'verb',\n",
       " 2: 'adp',\n",
       " 3: 'x',\n",
       " 4: 'prt',\n",
       " 5: 'adv',\n",
       " 6: 'adj',\n",
       " 7: 'conj',\n",
       " 8: 'noun',\n",
       " 9: 'det',\n",
       " 10: 'pron',\n",
       " 11: '.',\n",
       " 12: 'num',\n",
       " 0: '0'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_tags = {}\n",
    "for tag in unique_tags_dict:\n",
    "    index_to_tags[unique_tags_dict[tag]] = tag \n",
    "index_to_tags[0] = '0'\n",
    "index_to_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bottle', 'is', '5', 'years', 'old', ',', 'non', 'executive', 'director', 'of', 'CSK']\n",
      "[19137, 5291, 34264, 13742, 52999, 34315, 42468, 36097, 21093, 23101, 59449]\n",
      "bottle verb\n",
      "is verb\n",
      "5 adp\n",
      "years noun\n",
      "old adj\n",
      ", .\n",
      "non verb\n",
      "executive noun\n",
      "director noun\n",
      "of adp\n",
      "CSK det\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text = \"bottle is 5 years old, non executive director of CSK\"\n",
    "tokenized_seq = word_tokenize(text)\n",
    "print(tokenized_seq)\n",
    "\n",
    "tokens= prepare_TESTsequence_sentence(tokenized_seq,unique_words_dict)\n",
    "print(tokens) \n",
    "\n",
    "tokens = torch.tensor(tokens).to(device = device)\n",
    "tokens = tokens.unsqueeze(0)\n",
    "sample_gt = torch.zeros(1,len(tokens)).to(device=device)\n",
    "output = model(tokens,sample_gt)  #output shape 8,13,11 0:0,7:0 - same value, 0:1,7:1 - same value\n",
    "output2 = torch.zeros(output.shape[2],output.shape[1]).to(device=device) #shape 11,13\n",
    "\n",
    "index = 0\n",
    "for i in range(output.shape[2]): #loop over sequence length\n",
    "    a = output[0,:,index] # ashape [13]\n",
    "    a = a.unsqueeze(0)  #ashape [1,13]\n",
    "    output2[index,:] = a #index goes from 0 to 10 \n",
    "    index += 1\n",
    "\n",
    "tag_index = torch.argmax(output2,dim=1)\n",
    "#print(tag_index.shape)\n",
    "\n",
    "for predicted_tag,word in zip(tag_index,tokenized_seq):\n",
    "    predicted_tag = predicted_tag.item()\n",
    "    predicted_tag = index_to_tags[predicted_tag]\n",
    "    print(word, predicted_tag)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 13])\n",
      "torch.Size([13])\n",
      "torch.Size([1, 13])\n",
      "torch.Size([11, 13])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-6.7244, -1.0608, -2.3940, -3.3490, -3.6709, -2.3741, -1.7017, -6.2873,\n",
       "         -1.6192, -4.8119, -6.9129, -5.4197, -4.4345],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000]], device='cuda:0',\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2 = torch.zeros(output.shape[2],output.shape[1]).to(device=device)\n",
    "print(output2.shape)\n",
    "index = 0\n",
    "for i in range(output.shape[2]):\n",
    "    print(output[0,:,index].shape)\n",
    "    a = output[0,:,index]\n",
    "    a = a.unsqueeze(0)\n",
    "    print(a.shape)\n",
    "    output2[index,:] = a\n",
    "    index += 1\n",
    "    break\n",
    "print(output2.shape)\n",
    "#output3\n",
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 13, 11])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-11.3291,  -2.8417,  -3.6639,  -6.2068,  -4.4502,  -4.0068,  -2.2239,\n",
       "         -4.8807,  -1.3458,  -1.0197,  -2.8157,  -3.1231,  -3.1357],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0,:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-11.5816,  -0.1672,  -3.9647,  -5.4619,  -6.0741,  -4.2860,  -3.8301,\n",
       "         -9.1835,  -2.4143,  -7.8005,  -7.5994, -10.7598,  -5.9790],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 13, 11])\n"
     ]
    }
   ],
   "source": [
    "new = output.squeeze(0)\n",
    "print(new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
